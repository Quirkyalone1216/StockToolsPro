{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189a7f0b-d61c-44ac-8c56-50ac1d8bbb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/kenchen1216/StockTools/US_Stock\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_working_directory = os.getcwd()\n",
    "\n",
    "print(\"Current working directory:\", current_working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304659b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e06f7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available()) # Should be True\n",
    "print(torch.cuda.device_count()) # Should be > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f62a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 29 19:28:16 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.40.06              Driver Version: 551.23         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Quadro RTX 3000                On  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   46C    P8              4W /   80W |      13MiB /   6144MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        33      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d0f1d-d527-4b60-b305-3a4f5aabe0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "使用AutoGluon訓練模型\n",
    "波段交易的目標是捕捉股票價格的中短期波動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f3a78ca-f959-4bda-a8f2-a85a7f8b7681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: /home/kenchen1216/StockTools/US_Stock/models/2d_Future_model3/ds_sub_fit/sub_fit_ho.\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"/home/kenchen1216/StockTools/US_Stock/models/2d_Future_model3/ds_sub_fit/sub_fit_ho\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jan 11 04:09:03 UTC 2024\n",
      "CPU Count:          16\n",
      "Memory Avail:       28.73 GB / 31.24 GB (91.9%)\n",
      "Disk Space Avail:   877.91 GB / 1006.85 GB (87.2%)\n",
      "===================================================\n",
      "Train Data Rows:    1950663\n",
      "Train Data Columns: 18\n",
      "Label Column:       Future_Signal\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29388.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 267.88 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['Open', 'High', 'Low', 'Close', 'MA5', ...]\n",
      "\t\t('int', [])   :  4 | ['Volume', 'Signal', 'Pattern', 'OBV']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['Open', 'High', 'Low', 'Close', 'MA5', ...]\n",
      "\t\t('int', [])   :  4 | ['Volume', 'Signal', 'Pattern', 'OBV']\n",
      "\t6.3s = Fit runtime\n",
      "\t18 features in original data used to generate 18 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 267.88 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 6.94s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'TABPFN': {'N_ensemble_configurations': 8},\n",
      "\t'FT_TRANSFORMER': {},\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 15 L1 models ...\n",
      "Fitting model: TabPFN_BAG_L1 ... Training model for up to 595.22s of the 893.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have to download the TabPFN, as there is no checkpoint at  /home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/models_diff/prior_diff_real_checkpoint_n_0_epoch_100.cpkt\n",
      "It has about 100MB, so this might take a moment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused TabPFN_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t[enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 127838715904 bytes. Error code 12 (Cannot allocate memory)\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 273, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 689, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 315, in _fit_fold_model\n",
      "    fold_model, pred_proba = self._predict_oof(fold_model, fold_ctx)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 269, in _predict_oof\n",
      "    pred_proba = fold_model.predict_proba(X_val_fold)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 949, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 991, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py\", line 273, in predict_proba\n",
      "    prediction = transformer_predict(self.model[2], X_full, y_full, eval_pos,\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py\", line 528, in transformer_predict\n",
      "    output_batch = checkpoint(predict, batch_input, batch_label, style_, softmax_temperature_, True)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/utils/checkpoint.py\", line 249, in checkpoint\n",
      "    return CheckpointFunction.apply(function, preserve, *args)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/autograd/function.py\", line 506, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/utils/checkpoint.py\", line 107, in forward\n",
      "    outputs = run_function(*args)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py\", line 360, in predict\n",
      "    output = model(\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/transformer.py\", line 141, in forward\n",
      "    output = self.transformer_encoder(src, src_mask)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/transformer.py\", line 227, in forward\n",
      "    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/layer.py\", line 109, in forward\n",
      "    src_right = self.self_attn(src_[single_eval_position:], src_[:single_eval_position], src_[:single_eval_position])[0]\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/activation.py\", line 1205, in forward\n",
      "    attn_output, attn_output_weights = F.multi_head_attention_forward(\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/functional.py\", line 5338, in multi_head_attention_forward\n",
      "    attn_output_weights = torch.bmm(q_scaled, k.transpose(-2, -1))\n",
      "RuntimeError: [enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 127838715904 bytes. Error code 12 (Cannot allocate memory)\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 567.31s of the 865.14s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 2886.33s compared to 733.71s of available time.\n",
      "\tTime limit exceeded... Skipping KNeighborsUnif_BAG_L1.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 560.66s of the 858.5s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 2307.23s compared to 725.1s of available time.\n",
      "\tTime limit exceeded... Skipping KNeighborsDist_BAG_L1.\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 554.07s of the 851.9s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.95% memory usage per fold, 43.82%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=10.95%)\n",
      "/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/ray/_private/node.py:1160: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2024-03-30_14-45-23_528254_1559/logs/gcs_server.out' mode='a' encoding='utf-8'>\n",
      "  self.start_gcs_server()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/ray/_private/node.py:1160: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2024-03-30_14-45-23_528254_1559/logs/gcs_server.err' mode='a' encoding='utf-8'>\n",
      "  self.start_gcs_server()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/ray/_private/node.py:1165: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2024-03-30_14-45-23_528254_1559/logs/monitor.out' mode='a' encoding='utf-8'>\n",
      "  self.start_monitor()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/ray/_private/node.py:1165: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2024-03-30_14-45-23_528254_1559/logs/monitor.err' mode='a' encoding='utf-8'>\n",
      "  self.start_monitor()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/ray/_private/node.py:1181: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2024-03-30_14-45-23_528254_1559/logs/dashboard.err' mode='a' encoding='utf-8'>\n",
      "  self.start_api_server(\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/ray/_private/node.py:1223: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2024-03-30_14-45-23_528254_1559/logs/raylet.out' mode='a' encoding='utf-8'>\n",
      "  self.start_raylet(plasma_directory, object_store_memory)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/ray/_private/node.py:1223: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2024-03-30_14-45-23_528254_1559/logs/raylet.err' mode='a' encoding='utf-8'>\n",
      "  self.start_raylet(plasma_directory, object_store_memory)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/ray/_private/node.py:1225: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2024-03-30_14-45-23_528254_1559/logs/log_monitor.err' mode='a' encoding='utf-8'>\n",
      "  self.start_log_monitor()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "\t0.6545\t = Validation score   (accuracy)\n",
      "\t205.36s\t = Training   runtime\n",
      "\t13.09s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 336.74s of the 634.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=7.24%)\n",
      "\t0.6526\t = Validation score   (accuracy)\n",
      "\t271.62s\t = Training   runtime\n",
      "\t74.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 38.49s of the 336.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=7.25%)\n",
      "\t0.6487\t = Validation score   (accuracy)\n",
      "\t36.75s\t = Training   runtime\n",
      "\t3.94s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 287.89s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n",
      "\t0.6545\t = Validation score   (accuracy)\n",
      "\t139.64s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting 12 L2 models ...\n",
      "Fitting model: TabPFN_BAG_L2 ... Training model for up to 147.91s of the 147.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused TabPFN_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t[enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 127838715904 bytes. Error code 12 (Cannot allocate memory)\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 273, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 689, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 315, in _fit_fold_model\n",
      "    fold_model, pred_proba = self._predict_oof(fold_model, fold_ctx)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 269, in _predict_oof\n",
      "    pred_proba = fold_model.predict_proba(X_val_fold)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 949, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 991, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py\", line 273, in predict_proba\n",
      "    prediction = transformer_predict(self.model[2], X_full, y_full, eval_pos,\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py\", line 528, in transformer_predict\n",
      "    output_batch = checkpoint(predict, batch_input, batch_label, style_, softmax_temperature_, True)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/utils/checkpoint.py\", line 249, in checkpoint\n",
      "    return CheckpointFunction.apply(function, preserve, *args)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/autograd/function.py\", line 506, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/utils/checkpoint.py\", line 107, in forward\n",
      "    outputs = run_function(*args)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py\", line 360, in predict\n",
      "    output = model(\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/transformer.py\", line 141, in forward\n",
      "    output = self.transformer_encoder(src, src_mask)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/transformer.py\", line 227, in forward\n",
      "    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/layer.py\", line 109, in forward\n",
      "    src_right = self.self_attn(src_[single_eval_position:], src_[:single_eval_position], src_[:single_eval_position])[0]\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/activation.py\", line 1205, in forward\n",
      "    attn_output, attn_output_weights = F.multi_head_attention_forward(\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/functional.py\", line 5338, in multi_head_attention_forward\n",
      "    attn_output_weights = torch.bmm(q_scaled, k.transpose(-2, -1))\n",
      "RuntimeError: [enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 127838715904 bytes. Error code 12 (Cannot allocate memory)\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 122.88s of the 122.36s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.14% memory usage per fold, 60.57%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=15.14%)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
      "2024-03-30 14:58:00,535\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 91.11s of the 90.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=9.70%)\n",
      "\t0.6565\t = Validation score   (accuracy)\n",
      "\t82.78s\t = Training   runtime\n",
      "\t10.48s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -9.07s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.99, 'NeuralNetFastAI_BAG_L1': 0.01}\n",
      "\t0.6565\t = Validation score   (accuracy)\n",
      "\t157.17s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1066.82s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/kenchen1216/StockTools/US_Stock/models/2d_Future_model3/ds_sub_fit/sub_fit_ho\")\n",
      "Leaderboard on holdout data from dynamic stacking:\n",
      "                    model  holdout_score  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       LightGBMXT_BAG_L2       0.654731   0.656502    accuracy       30.088963     101.692728  596.519694                 2.080576               10.476982          82.781547            2       True          5\n",
      "1     WeightedEnsemble_L3       0.654678   0.656503    accuracy       30.101689     101.824366  753.686202                 0.012726                0.131638         157.166509            3       True          6\n",
      "2  NeuralNetFastAI_BAG_L1       0.654103   0.654463    accuracy       14.535051      13.086315  205.363809                14.535051               13.086315         205.363809            1       True          1\n",
      "3     WeightedEnsemble_L2       0.654103   0.654463    accuracy       14.546133      13.227868  345.002188                 0.011081                0.141552         139.638379            2       True          4\n",
      "4         LightGBM_BAG_L1       0.648062   0.648739    accuracy        0.734590       3.937300   36.751186                 0.734590                3.937300          36.751186            1       True          3\n",
      "5       LightGBMXT_BAG_L1       0.647509   0.652561    accuracy       12.738746      74.192130  271.623151                12.738746               74.192130         271.623151            1       True          2\n",
      "Stacked overfitting occurred: False.\n",
      "Spend 1098 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 2502 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 2502s\n",
      "AutoGluon will save models to \"/home/kenchen1216/StockTools/US_Stock/models/2d_Future_model3\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jan 11 04:09:03 UTC 2024\n",
      "CPU Count:          16\n",
      "Memory Avail:       27.04 GB / 31.24 GB (86.6%)\n",
      "Disk Space Avail:   877.82 GB / 1006.85 GB (87.2%)\n",
      "===================================================\n",
      "Train Data Rows:    2194496\n",
      "Train Data Columns: 18\n",
      "Label Column:       Future_Signal\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    27689.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 301.37 MB (1.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['Open', 'High', 'Low', 'Close', 'MA5', ...]\n",
      "\t\t('int', [])   :  4 | ['Volume', 'Signal', 'Pattern', 'OBV']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['Open', 'High', 'Low', 'Close', 'MA5', ...]\n",
      "\t\t('int', [])   :  4 | ['Volume', 'Signal', 'Pattern', 'OBV']\n",
      "\t8.6s = Fit runtime\n",
      "\t18 features in original data used to generate 18 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 301.37 MB (1.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 9.88s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'TABPFN': {'N_ensemble_configurations': 8},\n",
      "\t'FT_TRANSFORMER': {},\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 15 L1 models ...\n",
      "Fitting model: TabPFN_BAG_L1 ... Training model for up to 1661.0s of the 2492.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused TabPFN_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t[enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 143818489856 bytes. Error code 12 (Cannot allocate memory)\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 273, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 689, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 315, in _fit_fold_model\n",
      "    fold_model, pred_proba = self._predict_oof(fold_model, fold_ctx)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 269, in _predict_oof\n",
      "    pred_proba = fold_model.predict_proba(X_val_fold)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 949, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 991, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py\", line 273, in predict_proba\n",
      "    prediction = transformer_predict(self.model[2], X_full, y_full, eval_pos,\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py\", line 528, in transformer_predict\n",
      "    output_batch = checkpoint(predict, batch_input, batch_label, style_, softmax_temperature_, True)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/utils/checkpoint.py\", line 249, in checkpoint\n",
      "    return CheckpointFunction.apply(function, preserve, *args)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/autograd/function.py\", line 506, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/utils/checkpoint.py\", line 107, in forward\n",
      "    outputs = run_function(*args)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py\", line 360, in predict\n",
      "    output = model(\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/transformer.py\", line 141, in forward\n",
      "    output = self.transformer_encoder(src, src_mask)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/transformer.py\", line 227, in forward\n",
      "    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/layer.py\", line 109, in forward\n",
      "    src_right = self.self_attn(src_[single_eval_position:], src_[:single_eval_position], src_[:single_eval_position])[0]\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/activation.py\", line 1205, in forward\n",
      "    attn_output, attn_output_weights = F.multi_head_attention_forward(\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/functional.py\", line 5338, in multi_head_attention_forward\n",
      "    attn_output_weights = torch.bmm(q_scaled, k.transpose(-2, -1))\n",
      "RuntimeError: [enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 143818489856 bytes. Error code 12 (Cannot allocate memory)\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1638.06s of the 2469.18s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 3929.67s compared to 2119.69s of available time.\n",
      "\tTime limit exceeded... Skipping KNeighborsUnif_BAG_L1.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1622.3s of the 2453.42s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 3596.05s compared to 2100.53s of available time.\n",
      "\tTime limit exceeded... Skipping KNeighborsDist_BAG_L1.\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1608.05s of the 2439.17s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.73% memory usage per fold, 50.94%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=12.73%)\n",
      "\t0.6558\t = Validation score   (accuracy)\n",
      "\t890.56s\t = Training   runtime\n",
      "\t19.85s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 703.74s of the 1534.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=8.15%)\n",
      "\t0.6528\t = Validation score   (accuracy)\n",
      "\t570.15s\t = Training   runtime\n",
      "\t255.84s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 62.24s of the 893.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=8.15%)\n",
      "\t0.6553\t = Validation score   (accuracy)\n",
      "\t57.56s\t = Training   runtime\n",
      "\t8.15s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 822.93s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.949, 'LightGBM_BAG_L1': 0.04, 'LightGBMXT_BAG_L1': 0.01}\n",
      "\t0.6559\t = Validation score   (accuracy)\n",
      "\t152.24s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting 12 L2 models ...\n",
      "Fitting model: TabPFN_BAG_L2 ... Training model for up to 670.23s of the 669.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused TabPFN_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t[enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 143818489856 bytes. Error code 12 (Cannot allocate memory)\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 273, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 689, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 315, in _fit_fold_model\n",
      "    fold_model, pred_proba = self._predict_oof(fold_model, fold_ctx)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 269, in _predict_oof\n",
      "    pred_proba = fold_model.predict_proba(X_val_fold)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 949, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 991, in _predict_proba\n",
      "    y_pred_proba = self.model.predict_proba(X)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py\", line 273, in predict_proba\n",
      "    prediction = transformer_predict(self.model[2], X_full, y_full, eval_pos,\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py\", line 528, in transformer_predict\n",
      "    output_batch = checkpoint(predict, batch_input, batch_label, style_, softmax_temperature_, True)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/utils/checkpoint.py\", line 249, in checkpoint\n",
      "    return CheckpointFunction.apply(function, preserve, *args)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/autograd/function.py\", line 506, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/utils/checkpoint.py\", line 107, in forward\n",
      "    outputs = run_function(*args)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/scripts/transformer_prediction_interface.py\", line 360, in predict\n",
      "    output = model(\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/transformer.py\", line 141, in forward\n",
      "    output = self.transformer_encoder(src, src_mask)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/transformer.py\", line 227, in forward\n",
      "    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/tabpfn/layer.py\", line 109, in forward\n",
      "    src_right = self.self_attn(src_[single_eval_position:], src_[:single_eval_position], src_[:single_eval_position])[0]\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/modules/activation.py\", line 1205, in forward\n",
      "    attn_output, attn_output_weights = F.multi_head_attention_forward(\n",
      "  File \"/home/kenchen1216/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/torch/nn/functional.py\", line 5338, in multi_head_attention_forward\n",
      "    attn_output_weights = torch.bmm(q_scaled, k.transpose(-2, -1))\n",
      "RuntimeError: [enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 143818489856 bytes. Error code 12 (Cannot allocate memory)\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 643.44s of the 642.85s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.00% memory usage per fold, 68.01%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=17.00%)\n",
      "\t0.6586\t = Validation score   (accuracy)\n",
      "\t365.69s\t = Training   runtime\n",
      "\t19.87s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 259.23s of the 258.62s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.91% memory usage per fold, 43.62%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=4, gpus=0, memory=10.91%)\n",
      "\t0.6588\t = Validation score   (accuracy)\n",
      "\t226.64s\t = Training   runtime\n",
      "\t18.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 17.17s of the 16.58s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.90% memory usage per fold, 43.61%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=4, gpus=0, memory=10.90%)\n",
      "\t0.6425\t = Validation score   (accuracy)\n",
      "\t31.12s\t = Training   runtime\n",
      "\t1.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -30.3s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
      "\t0.6588\t = Validation score   (accuracy)\n",
      "\t216.15s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2749.17s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/kenchen1216/StockTools/US_Stock/models/2d_Future_model3\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6586860946659279, 'balanced_accuracy': 0.28059334096779304, 'mcc': 0.16846901763989977}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 步骤1: 合并CSV文件\n",
    "def combine_csv_files(folder_path):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            temp_df = pd.read_csv(file_path)\n",
    "            combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n",
    "    combined_df = combined_df.dropna()\n",
    "    return combined_df\n",
    "\n",
    "# 步骤3: 分割数据集\n",
    "def split_data(df):\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    return train_df, test_df\n",
    "\n",
    "# 步骤4: 使用AutoGluon训练模型并启用GPU加速\n",
    "def train_model(train_df, label_column='Future_Signal'):\n",
    "    model_path = '/home/kenchen1216/StockTools/US_Stock/models/2d_Future_model3'\n",
    "    predictor = TabularPredictor(label=label_column, path=model_path).fit(train_data=train_df, presets='best_quality', num_gpus=1 ,\n",
    "                                                                          hyperparameters='extreme') # Grant 1 gpu for the entire Tabular Predictor\n",
    "    return predictor\n",
    "\n",
    "# 步骤5: 评估模型\n",
    "def evaluate_model(predictor, test_df):\n",
    "    predictor.leaderboard(test_df)\n",
    "    performance = predictor.evaluate(test_df)\n",
    "    print(performance)\n",
    "\n",
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = '/home/kenchen1216/StockTools/US_Stock/ProcessData/ProcessData 3'  # 修改为你的文件夹路径\n",
    "    combined_df = combine_csv_files(folder_path)\n",
    "    train_df, test_df = split_data(combined_df)\n",
    "    predictor = train_model(train_df, label_column='Future_Signal')\n",
    "    evaluate_model(predictor, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f59e6-4fe6-4b68-ab42-9aeb72431263",
   "metadata": {},
   "outputs": [],
   "source": [
    "使用AutoGluon訓練模型\n",
    "時間序列預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42aa3ce9-c706-4fd2-8829-e09ec2ff7497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"output_directory_path/3432.TW.csv\"\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to 'output_directory_path/3432.TW.csv'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jan 11 04:09:03 UTC 2024\n",
      "CPU Count:          16\n",
      "GPU Count:          1\n",
      "Memory Avail:       29.85 GB / 31.24 GB (95.6%)\n",
      "Disk Space Avail:   877.23 GB / 1006.85 GB (87.1%)\n",
      "===================================================\n",
      "Setting presets to: high_quality\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MAPE,\n",
      " 'freq': 'D',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 3,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'target': 'Close',\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'None' has been resampled to frequency 'D'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "處理檔案: /home/kenchen1216/StockTools/US_Stock/Daily_K/3432.TW.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_data contains missing values represented by NaN. They have been filled by carrying forward the last valid observation.\n",
      "Provided train_data has 4559 rows, 1 time series. Median time series length is 4559 (min=4559, max=4559). \n",
      "\n",
      "Provided dataset contains following columns:\n",
      "\ttarget:           'Close'\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-03-30 19:54:37\n",
      "Models that will be trained: ['SeasonalNaive', 'CrostonSBA', 'NPTS', 'AutoETS', 'DynamicOptimizedTheta', 'AutoARIMA', 'RecursiveTabular', 'DirectTabular', 'DeepAR', 'TemporalFusionTransformer', 'PatchTST']\n",
      "Training timeseries model SeasonalNaive. \n",
      "\t-0.0282       = Validation score (-MAPE)\n",
      "\t0.01    s     = Training runtime\n",
      "\t1.25    s     = Validation (prediction) runtime\n",
      "Training timeseries model CrostonSBA. \n",
      "\t-0.0426       = Validation score (-MAPE)\n",
      "\t0.01    s     = Training runtime\n",
      "\t7.22    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. \n",
      "\t-0.1395       = Validation score (-MAPE)\n",
      "\t0.01    s     = Training runtime\n",
      "\t0.84    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. \n",
      "\t-0.0099       = Validation score (-MAPE)\n",
      "\t0.01    s     = Training runtime\n",
      "\t21.14   s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. \n",
      "\t-0.0133       = Validation score (-MAPE)\n",
      "\t0.01    s     = Training runtime\n",
      "\t21.31   s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoARIMA. \n",
      "\t-0.0098       = Validation score (-MAPE)\n",
      "\t0.01    s     = Training runtime\n",
      "\t11.79   s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. \n",
      "\t-0.0117       = Validation score (-MAPE)\n",
      "\t9.75    s     = Training runtime\n",
      "\t0.77    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. \n",
      "\t-0.1281       = Validation score (-MAPE)\n",
      "\t0.73    s     = Training runtime\n",
      "\t0.07    s     = Validation (prediction) runtime\n",
      "Training timeseries model DeepAR. \n",
      "\t-0.0053       = Validation score (-MAPE)\n",
      "\t32.39   s     = Training runtime\n",
      "\t0.05    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. \n",
      "\t-0.0042       = Validation score (-MAPE)\n",
      "\t64.77   s     = Training runtime\n",
      "\t0.02    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. \n",
      "\t-0.0084       = Validation score (-MAPE)\n",
      "\t44.37   s     = Training runtime\n",
      "\t0.03    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoARIMA': 0.35, 'DeepAR': 0.44, 'PatchTST': 0.02, 'SeasonalNaive': 0.09, 'TemporalFusionTransformer': 0.11}\n",
      "\t-0.0012       = Validation score (-MAPE)\n",
      "\t1.07    s     = Training runtime\n",
      "\t13.13   s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'CrostonSBA', 'NPTS', 'AutoETS', 'DynamicOptimizedTheta', 'AutoARIMA', 'RecursiveTabular', 'DirectTabular', 'DeepAR', 'TemporalFusionTransformer', 'PatchTST', 'WeightedEnsemble']\n",
      "Total runtime: 218.24 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.0012\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "\tWarning: AutoARIMA/W0 failed for 1 time series (100.0%). Fallback model SeasonalNaive was used for these time series.\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/kenchen1216/StockTools/US_Stock/TWPredictedData/TimeSeries/3432.TW.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# 將預測結果保存到CSV檔案中\u001b[39;00m\n\u001b[1;32m     48\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(predict_path, filename)\n\u001b[0;32m---> 49\u001b[0m \u001b[43mforecast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m預測結果已儲存到 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3900\u001b[0m )\n\u001b[0;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3905\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/pandas/io/formats/format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1151\u001b[0m )\n\u001b[0;32m-> 1152\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/pandas/io/formats/csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/miniconda3/envs/AutoGluon/lib/python3.9/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/home/kenchen1216/StockTools/US_Stock/TWPredictedData/TimeSeries/3432.TW.csv'"
     ]
    }
   ],
   "source": [
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 設定目錄路徑\n",
    "directory_path = '/home/kenchen1216/StockTools/US_Stock/Daily_K'\n",
    "output_directory_path = '/home/kenchen1216/StockTools/US_Stock/models/TimeSeries'  # 預測結果儲存的目錄\n",
    "predict_path = '/home/kenchen1216/StockTools/US_Stock/TWPredictedData/TimeSeries'\n",
    "\n",
    "# 確保輸出目錄存在\n",
    "os.makedirs(output_directory_path, exist_ok=True)\n",
    "\n",
    "# 遍歷目錄中的所有CSV檔案\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        print(f\"處理檔案: {file_path}\")\n",
    "\n",
    "        # 載入數據\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # 預處理（確保時間戳的格式正確）\n",
    "        data['timestamp'] = pd.to_datetime(data['Date']).dt.tz_localize(None)\n",
    "        data.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "        data = TimeSeriesDataFrame.from_data_frame(data, id_column=\"item_id\", timestamp_column=\"timestamp\") \n",
    "        model_path = os.path.join(output_directory_path, filename)\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        # 初始化時間序列預測器，設置預測未來3天\n",
    "        predictor = TimeSeriesPredictor(\n",
    "            path=model_path,  # 為每個檔案創建獨立的模型目錄\n",
    "            prediction_length=3,  # 預測未來3天的收盤價\n",
    "            target='Close',  # 我们要预测的目标变量\n",
    "            eval_metric=\"MAPE\",\n",
    "            freq='D'  # 假設為每日數據。根據您數據的頻率調整此設定\n",
    "        )\n",
    "\n",
    "        # 訓練模型\n",
    "        predictor.fit(\n",
    "            train_data=data,\n",
    "            hyperparameters='default',  # 使用預設的超參數\n",
    "            presets=\"high_quality\"\n",
    "        )\n",
    "\n",
    "        # 進行預測\n",
    "        forecast = predictor.predict(data.tail(predictor.prediction_length))\n",
    "\n",
    "        # 將預測結果保存到CSV檔案中\n",
    "        output_file_path = os.path.join(predict_path, filename)\n",
    "        forecast.to_csv(output_file_path, index=False)\n",
    "\n",
    "        print(f\"預測結果已儲存到 {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

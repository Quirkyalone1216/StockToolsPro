{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189a7f0b-d61c-44ac-8c56-50ac1d8bbb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: d:\\Python\\StockToolsPro\\AutoGluon\\TrainModel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_working_directory = os.getcwd()\n",
    "\n",
    "print(\"Current working directory:\", current_working_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2dd960",
   "metadata": {},
   "source": [
    "查看torch 是否成功安裝，然後查看GPU是否可用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c38f1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch installed version: 2.0.1\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if torch is installed\n",
    "print(\"Torch installed version:\", torch.__version__)\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59afe99d",
   "metadata": {},
   "source": [
    "顯卡資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26d03d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 14 01:47:23 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.23                 Driver Version: 551.23         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Quadro RTX 3000              WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   53C    P8              6W /   80W |       0MiB /   6144MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bcf2f2",
   "metadata": {},
   "source": [
    "針對美股訓練數據中的Signal欄位做訓練\n",
    "y --> Signal欄位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dc58cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"D:\\Temp\\StockData\\model\\AutoGluon\\SwingTradeSignals\\SwingTrade-1\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: D:\\Temp\\StockData\\model\\AutoGluon\\SwingTradeSignals\\SwingTrade-1/ds_sub_fit/sub_fit_ho.\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"D:\\Temp\\StockData\\model\\AutoGluon\\SwingTradeSignals\\SwingTrade-1/ds_sub_fit/sub_fit_ho\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "CPU Count:          16\n",
      "Memory Avail:       37.70 GB / 63.79 GB (59.1%)\n",
      "Disk Space Avail:   1095.12 GB / 1907.71 GB (57.4%)\n",
      "===================================================\n",
      "Train Data Rows:    219193\n",
      "Train Data Columns: 5\n",
      "Label Column:       Signal\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 2.0, class 0 = 1.0\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (2.0) vs negative (1.0) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    38523.45 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['Open', 'High', 'Low', 'Close']\n",
      "\t\t('int', [])   : 1 | ['Volume']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['Open', 'High', 'Low', 'Close']\n",
      "\t\t('int', [])   : 1 | ['Volume']\n",
      "\t0.3s = Fit runtime\n",
      "\t5 features in original data used to generate 5 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.36 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.4s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'TABPFN': {'N_ensemble_configurations': 8},\n",
      "\t'FT_TRANSFORMER': {},\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 15 L1 models ...\n",
      "Fitting model: TabPFN_BAG_L1 ... Training model for up to 599.58s of the 899.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused TabPFN_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tNo module named 'tabpfn'\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 599.26s of the 899.28s of remaining time.\n",
      "\t0.5196\t = Validation score   (accuracy)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 597.79s of the 897.81s of remaining time.\n",
      "\t0.525\t = Validation score   (accuracy)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 596.15s of the 896.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.34646\n",
      "[2000]\tvalid_set's binary_error: 0.307737\n",
      "[3000]\tvalid_set's binary_error: 0.289453\n",
      "[4000]\tvalid_set's binary_error: 0.274197\n",
      "[5000]\tvalid_set's binary_error: 0.267007\n",
      "[6000]\tvalid_set's binary_error: 0.257007\n",
      "[7000]\tvalid_set's binary_error: 0.251058\n",
      "[8000]\tvalid_set's binary_error: 0.247774\n",
      "[9000]\tvalid_set's binary_error: 0.245365\n",
      "[10000]\tvalid_set's binary_error: 0.242117\n",
      "[1000]\tvalid_set's binary_error: 0.346071\n",
      "[2000]\tvalid_set's binary_error: 0.308916\n",
      "[3000]\tvalid_set's binary_error: 0.289609\n",
      "[4000]\tvalid_set's binary_error: 0.276944\n",
      "[5000]\tvalid_set's binary_error: 0.268805\n",
      "[6000]\tvalid_set's binary_error: 0.26125\n",
      "[7000]\tvalid_set's binary_error: 0.255703\n",
      "[8000]\tvalid_set's binary_error: 0.252527\n",
      "[9000]\tvalid_set's binary_error: 0.248513\n",
      "[10000]\tvalid_set's binary_error: 0.245556\n",
      "[1000]\tvalid_set's binary_error: 0.350341\n",
      "[2000]\tvalid_set's binary_error: 0.313515\n",
      "[3000]\tvalid_set's binary_error: 0.292857\n",
      "[4000]\tvalid_set's binary_error: 0.277674\n",
      "[5000]\tvalid_set's binary_error: 0.267455\n",
      "[6000]\tvalid_set's binary_error: 0.259936\n",
      "[7000]\tvalid_set's binary_error: 0.254535\n",
      "[8000]\tvalid_set's binary_error: 0.250046\n",
      "[9000]\tvalid_set's binary_error: 0.245593\n",
      "[10000]\tvalid_set's binary_error: 0.243294\n",
      "[1000]\tvalid_set's binary_error: 0.3441\n",
      "[2000]\tvalid_set's binary_error: 0.309172\n",
      "[3000]\tvalid_set's binary_error: 0.289682\n",
      "[4000]\tvalid_set's binary_error: 0.278477\n",
      "[5000]\tvalid_set's binary_error: 0.268404\n",
      "[6000]\tvalid_set's binary_error: 0.258878\n",
      "[7000]\tvalid_set's binary_error: 0.25333\n",
      "[8000]\tvalid_set's binary_error: 0.246724\n",
      "[9000]\tvalid_set's binary_error: 0.243549\n",
      "[10000]\tvalid_set's binary_error: 0.240118\n",
      "[1000]\tvalid_set's binary_error: 0.349246\n",
      "[2000]\tvalid_set's binary_error: 0.312895\n",
      "[3000]\tvalid_set's binary_error: 0.295449\n",
      "[4000]\tvalid_set's binary_error: 0.281616\n",
      "[5000]\tvalid_set's binary_error: 0.271324\n",
      "[6000]\tvalid_set's binary_error: 0.264024\n",
      "[7000]\tvalid_set's binary_error: 0.258732\n",
      "[8000]\tvalid_set's binary_error: 0.252929\n",
      "[9000]\tvalid_set's binary_error: 0.249535\n",
      "[10000]\tvalid_set's binary_error: 0.247089\n",
      "[1000]\tvalid_set's binary_error: 0.344757\n",
      "[2000]\tvalid_set's binary_error: 0.310303\n",
      "[3000]\tvalid_set's binary_error: 0.289062\n",
      "[4000]\tvalid_set's binary_error: 0.276835\n",
      "[5000]\tvalid_set's binary_error: 0.267966\n",
      "[6000]\tvalid_set's binary_error: 0.261177\n",
      "[7000]\tvalid_set's binary_error: 0.255046\n",
      "[8000]\tvalid_set's binary_error: 0.25063\n",
      "[9000]\tvalid_set's binary_error: 0.246578\n",
      "[10000]\tvalid_set's binary_error: 0.243513\n",
      "[1000]\tvalid_set's binary_error: 0.347713\n",
      "[2000]\tvalid_set's binary_error: 0.314829\n",
      "[3000]\tvalid_set's binary_error: 0.295339\n",
      "[4000]\tvalid_set's binary_error: 0.28304\n",
      "[5000]\tvalid_set's binary_error: 0.275339\n",
      "[6000]\tvalid_set's binary_error: 0.268769\n",
      "[7000]\tvalid_set's binary_error: 0.262637\n",
      "[8000]\tvalid_set's binary_error: 0.258367\n",
      "[9000]\tvalid_set's binary_error: 0.255265\n",
      "[10000]\tvalid_set's binary_error: 0.252308\n",
      "[1000]\tvalid_set's binary_error: 0.346327\n",
      "[2000]\tvalid_set's binary_error: 0.312603\n",
      "[3000]\tvalid_set's binary_error: 0.292748\n",
      "[4000]\tvalid_set's binary_error: 0.28085\n",
      "[5000]\tvalid_set's binary_error: 0.270959\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m combine_csv_files(folder_path)\n\u001b[0;32m     41\u001b[0m train_df, test_df \u001b[38;5;241m=\u001b[39m split_data(combined_df)\n\u001b[1;32m---> 42\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSignal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m evaluate_model(predictor, test_df)\n",
      "Cell \u001b[1;32mIn[9], line 25\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(train_df, label_column)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(train_df, label_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSignal\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     24\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTemp\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mStockData\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAutoGluon\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSwingTradeSignals\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSwingTrade-1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 25\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[43mTabularPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_quality\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                                                          \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mextreme\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 為整個Tabular Predictor指定1個GPU\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictor\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39mother_args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39mgargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgkwargs)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1099\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_stacking:\n\u001b[0;32m   1094\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog(\n\u001b[0;32m   1095\u001b[0m         \u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m   1096\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDynamic stacking is enabled (dynamic_stacking=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdynamic_stacking\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1098\u001b[0m     )\n\u001b[1;32m-> 1099\u001b[0m     num_stack_levels, time_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynamic_stacking(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mds_args, ag_fit_kwargs\u001b[38;5;241m=\u001b[39mag_fit_kwargs, ag_post_fit_kwargs\u001b[38;5;241m=\u001b[39mag_post_fit_kwargs)\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (time_limit \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough time left to train models for the full fit. Consider specifying a larger time_limit. Time remaining: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_limit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m         )\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1186\u001b[0m, in \u001b[0;36mTabularPredictor._dynamic_stacking\u001b[1;34m(self, ag_fit_kwargs, ag_post_fit_kwargs, validation_procedure, detection_time_frac, holdout_frac, n_folds, n_repeats, memory_safe_fits, clean_up_fits, holdout_data)\u001b[0m\n\u001b[0;32m   1181\u001b[0m         ds_fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mds_fit_context\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ds_fit_context \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/sub_fit_custom_ho\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1182\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   1183\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting holdout-based sub-fit for dynamic stacking with custom validation data. Context path is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds_fit_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds_fit_context\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1184\u001b[0m         )\n\u001b[1;32m-> 1186\u001b[0m     stacked_overfitting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sub_fit_memory_save_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_ag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_ag_post_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mholdout_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mholdout_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1195\u001b[0m     \u001b[38;5;66;03m# Holdout is false, use (repeated) cross-validation\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m     is_stratified \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;129;01min\u001b[39;00m [REGRESSION, QUANTILE, SOFTCLASS]\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1336\u001b[0m, in \u001b[0;36mTabularPredictor._sub_fit_memory_save_wrapper\u001b[1;34m(self, train_data, time_limit, ds_fit_kwargs, ag_fit_kwargs, ag_post_fit_kwargs, holdout_data)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     normal_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normal_fit:\n\u001b[1;32m-> 1336\u001b[0m     stacked_overfitting \u001b[38;5;241m=\u001b[39m \u001b[43m_sub_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mholdout_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mholdout_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1344\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stacked_overfitting\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:4897\u001b[0m, in \u001b[0;36m_sub_fit\u001b[1;34m(predictor, train_data, time_limit, ds_fit_kwargs, ag_fit_kwargs, ag_post_fit_kwargs, holdout_data)\u001b[0m\n\u001b[0;32m   4894\u001b[0m clean_up_fits \u001b[38;5;241m=\u001b[39m ds_fit_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean_up_fits\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4896\u001b[0m predictor\u001b[38;5;241m.\u001b[39m_learner\u001b[38;5;241m.\u001b[39mset_contexts(path_context\u001b[38;5;241m=\u001b[39mds_fit_context)\n\u001b[1;32m-> 4897\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predictor\u001b[38;5;241m.\u001b[39mmodel_names():\n\u001b[0;32m   4900\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to determine stacked overfitting. AutoGluon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms sub-fit did not successfully train any models!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1115\u001b[0m, in \u001b[0;36mTabularPredictor._fit\u001b[1;34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[0m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, ag_fit_kwargs: \u001b[38;5;28mdict\u001b[39m, ag_post_fit_kwargs: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[1;32m-> 1115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learner\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag_fit_kwargs)\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_post_fit_vars()\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_fit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag_post_fit_kwargs)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py:159\u001b[0m, in \u001b[0;36mAbstractTabularLearner.fit\u001b[1;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearner is already fit.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_fit_input(X\u001b[38;5;241m=\u001b[39mX, X_val\u001b[38;5;241m=\u001b[39mX_val, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X\u001b[38;5;241m=\u001b[39mX, X_val\u001b[38;5;241m=\u001b[39mX_val, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:128\u001b[0m, in \u001b[0;36mDefaultLearner._fit\u001b[1;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_metric \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39meval_metric\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m--> 128\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    129\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    130\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    131\u001b[0m     X_val\u001b[38;5;241m=\u001b[39mX_val,\n\u001b[0;32m    132\u001b[0m     y_val\u001b[38;5;241m=\u001b[39my_val,\n\u001b[0;32m    133\u001b[0m     X_unlabeled\u001b[38;5;241m=\u001b[39mX_unlabeled,\n\u001b[0;32m    134\u001b[0m     holdout_frac\u001b[38;5;241m=\u001b[39mholdout_frac,\n\u001b[0;32m    135\u001b[0m     time_limit\u001b[38;5;241m=\u001b[39mtime_limit_trainer,\n\u001b[0;32m    136\u001b[0m     infer_limit\u001b[38;5;241m=\u001b[39minfer_limit,\n\u001b[0;32m    137\u001b[0m     infer_limit_batch_size\u001b[38;5;241m=\u001b[39minfer_limit_batch_size,\n\u001b[0;32m    138\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrainer_fit_kwargs,\n\u001b[0;32m    140\u001b[0m )\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_trainer(trainer\u001b[38;5;241m=\u001b[39mtrainer)\n\u001b[0;32m    142\u001b[0m time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py:125\u001b[0m, in \u001b[0;36mAutoTrainer.fit\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m log_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m20\u001b[39m, log_str)\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_multi_and_ensemble\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_stack_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_stack_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maux_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maux_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2503\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_and_ensemble\u001b[1;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[0;32m   2501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_rows_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_val)\n\u001b[0;32m   2502\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_cols_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m-> 2503\u001b[0m model_names_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_multi_levels(\n\u001b[0;32m   2504\u001b[0m     X,\n\u001b[0;32m   2505\u001b[0m     y,\n\u001b[0;32m   2506\u001b[0m     hyperparameters\u001b[38;5;241m=\u001b[39mhyperparameters,\n\u001b[0;32m   2507\u001b[0m     X_val\u001b[38;5;241m=\u001b[39mX_val,\n\u001b[0;32m   2508\u001b[0m     y_val\u001b[38;5;241m=\u001b[39my_val,\n\u001b[0;32m   2509\u001b[0m     X_unlabeled\u001b[38;5;241m=\u001b[39mX_unlabeled,\n\u001b[0;32m   2510\u001b[0m     level_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   2511\u001b[0m     level_end\u001b[38;5;241m=\u001b[39mnum_stack_levels \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   2512\u001b[0m     time_limit\u001b[38;5;241m=\u001b[39mtime_limit,\n\u001b[0;32m   2513\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2514\u001b[0m )\n\u001b[0;32m   2515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2516\u001b[0m     \u001b[38;5;66;03m# TODO v1.0: Add toggle to raise exception if no models trained\u001b[39;00m\n\u001b[0;32m   2517\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: AutoGluon did not successfully train any models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:388\u001b[0m, in \u001b[0;36mAbstractTrainer.train_multi_levels\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[0;32m    386\u001b[0m         core_kwargs_level[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m core_kwargs_level\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m, time_limit_core)\n\u001b[0;32m    387\u001b[0m         aux_kwargs_level[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m aux_kwargs_level\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m, time_limit_aux)\n\u001b[1;32m--> 388\u001b[0m     base_model_names, aux_models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_new_level\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_model_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_model_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcore_kwargs_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43maux_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maux_kwargs_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname_suffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_weighted_ensemble\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_weighted_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_full_weighted_ensemble\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_full_weighted_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m     model_names_fit \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m base_model_names \u001b[38;5;241m+\u001b[39m aux_models\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model_names_fit) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:536\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size, full_weighted_ensemble, additional_full_weighted_ensemble)\u001b[0m\n\u001b[0;32m    534\u001b[0m     core_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_suffix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m core_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_suffix\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m name_suffix\n\u001b[0;32m    535\u001b[0m     aux_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_suffix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m aux_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_suffix\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m name_suffix\n\u001b[1;32m--> 536\u001b[0m core_models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_new_level_core(\n\u001b[0;32m    537\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    538\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    539\u001b[0m     X_val\u001b[38;5;241m=\u001b[39mX_val,\n\u001b[0;32m    540\u001b[0m     y_val\u001b[38;5;241m=\u001b[39my_val,\n\u001b[0;32m    541\u001b[0m     X_unlabeled\u001b[38;5;241m=\u001b[39mX_unlabeled,\n\u001b[0;32m    542\u001b[0m     models\u001b[38;5;241m=\u001b[39mmodels,\n\u001b[0;32m    543\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m    544\u001b[0m     infer_limit\u001b[38;5;241m=\u001b[39minfer_limit,\n\u001b[0;32m    545\u001b[0m     infer_limit_batch_size\u001b[38;5;241m=\u001b[39minfer_limit_batch_size,\n\u001b[0;32m    546\u001b[0m     base_model_names\u001b[38;5;241m=\u001b[39mbase_model_names,\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcore_kwargs,\n\u001b[0;32m    548\u001b[0m )\n\u001b[0;32m    550\u001b[0m aux_models \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_weighted_ensemble:\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:666\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level_core\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    663\u001b[0m fit_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)\n\u001b[0;32m    665\u001b[0m \u001b[38;5;66;03m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[39;00m\n\u001b[1;32m--> 666\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_multi(\n\u001b[0;32m    667\u001b[0m     X\u001b[38;5;241m=\u001b[39mX_init,\n\u001b[0;32m    668\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    669\u001b[0m     X_val\u001b[38;5;241m=\u001b[39mX_val,\n\u001b[0;32m    670\u001b[0m     y_val\u001b[38;5;241m=\u001b[39my_val,\n\u001b[0;32m    671\u001b[0m     X_unlabeled\u001b[38;5;241m=\u001b[39mX_unlabeled,\n\u001b[0;32m    672\u001b[0m     models\u001b[38;5;241m=\u001b[39mmodels,\n\u001b[0;32m    673\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m    674\u001b[0m     stack_name\u001b[38;5;241m=\u001b[39mstack_name,\n\u001b[0;32m    675\u001b[0m     compute_score\u001b[38;5;241m=\u001b[39mcompute_score,\n\u001b[0;32m    676\u001b[0m     fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    678\u001b[0m )\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2453\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi\u001b[1;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_repeat_start \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2452\u001b[0m     time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m-> 2453\u001b[0m     model_names_trained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_multi_initial(\n\u001b[0;32m   2454\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   2455\u001b[0m         y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   2456\u001b[0m         models\u001b[38;5;241m=\u001b[39mmodels,\n\u001b[0;32m   2457\u001b[0m         k_fold\u001b[38;5;241m=\u001b[39mk_fold,\n\u001b[0;32m   2458\u001b[0m         n_repeats\u001b[38;5;241m=\u001b[39mn_repeats_initial,\n\u001b[0;32m   2459\u001b[0m         hyperparameter_tune_kwargs\u001b[38;5;241m=\u001b[39mhyperparameter_tune_kwargs,\n\u001b[0;32m   2460\u001b[0m         feature_prune_kwargs\u001b[38;5;241m=\u001b[39mfeature_prune_kwargs,\n\u001b[0;32m   2461\u001b[0m         time_limit\u001b[38;5;241m=\u001b[39mtime_limit,\n\u001b[0;32m   2462\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2463\u001b[0m     )\n\u001b[0;32m   2464\u001b[0m     n_repeat_start \u001b[38;5;241m=\u001b[39m n_repeats_initial\n\u001b[0;32m   2465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2302\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_initial\u001b[1;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   2300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2301\u001b[0m     time_ratio \u001b[38;5;241m=\u001b[39m hpo_time_ratio \u001b[38;5;28;01mif\u001b[39;00m hpo_enabled \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 2302\u001b[0m     models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_multi_fold(\n\u001b[0;32m   2303\u001b[0m         models\u001b[38;5;241m=\u001b[39mmodels,\n\u001b[0;32m   2304\u001b[0m         hyperparameter_tune_kwargs\u001b[38;5;241m=\u001b[39mhyperparameter_tune_kwargs,\n\u001b[0;32m   2305\u001b[0m         k_fold_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2306\u001b[0m         k_fold_end\u001b[38;5;241m=\u001b[39mk_fold,\n\u001b[0;32m   2307\u001b[0m         n_repeats\u001b[38;5;241m=\u001b[39mn_repeats,\n\u001b[0;32m   2308\u001b[0m         n_repeat_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2309\u001b[0m         time_limit\u001b[38;5;241m=\u001b[39mtime_limit,\n\u001b[0;32m   2310\u001b[0m         time_split\u001b[38;5;241m=\u001b[39mtime_split,\n\u001b[0;32m   2311\u001b[0m         time_ratio\u001b[38;5;241m=\u001b[39mtime_ratio,\n\u001b[0;32m   2312\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args,\n\u001b[0;32m   2313\u001b[0m     )\n\u001b[0;32m   2315\u001b[0m multi_fold_time_elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m multi_fold_time_start\n\u001b[0;32m   2316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2410\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_fold\u001b[1;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   2408\u001b[0m         time_start_model \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   2409\u001b[0m         time_left \u001b[38;5;241m=\u001b[39m time_limit \u001b[38;5;241m-\u001b[39m (time_start_model \u001b[38;5;241m-\u001b[39m time_start)\n\u001b[1;32m-> 2410\u001b[0m model_name_trained_lst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_single_full(\n\u001b[0;32m   2411\u001b[0m     X, y, model, time_limit\u001b[38;5;241m=\u001b[39mtime_left, hyperparameter_tune_kwargs\u001b[38;5;241m=\u001b[39mhyperparameter_tune_kwargs_model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   2412\u001b[0m )\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m   2415\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m model\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2183\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single_full\u001b[1;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[0;32m   2179\u001b[0m         bagged_model_fit_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_bagged_model_fit_kwargs(\n\u001b[0;32m   2180\u001b[0m             k_fold\u001b[38;5;241m=\u001b[39mk_fold, k_fold_start\u001b[38;5;241m=\u001b[39mk_fold_start, k_fold_end\u001b[38;5;241m=\u001b[39mk_fold_end, n_repeats\u001b[38;5;241m=\u001b[39mn_repeats, n_repeat_start\u001b[38;5;241m=\u001b[39mn_repeat_start\n\u001b[0;32m   2181\u001b[0m         )\n\u001b[0;32m   2182\u001b[0m         model_fit_kwargs\u001b[38;5;241m.\u001b[39mupdate(bagged_model_fit_kwargs)\n\u001b[1;32m-> 2183\u001b[0m     model_names_trained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_and_save(\n\u001b[0;32m   2184\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   2185\u001b[0m         y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   2186\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   2187\u001b[0m         X_val\u001b[38;5;241m=\u001b[39mX_val,\n\u001b[0;32m   2188\u001b[0m         y_val\u001b[38;5;241m=\u001b[39my_val,\n\u001b[0;32m   2189\u001b[0m         X_unlabeled\u001b[38;5;241m=\u001b[39mX_unlabeled,\n\u001b[0;32m   2190\u001b[0m         stack_name\u001b[38;5;241m=\u001b[39mstack_name,\n\u001b[0;32m   2191\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   2192\u001b[0m         compute_score\u001b[38;5;241m=\u001b[39mcompute_score,\n\u001b[0;32m   2193\u001b[0m         total_resources\u001b[38;5;241m=\u001b[39mtotal_resources,\n\u001b[0;32m   2194\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_fit_kwargs,\n\u001b[0;32m   2195\u001b[0m     )\n\u001b[0;32m   2196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   2197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_names_trained\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1817\u001b[0m, in \u001b[0;36mAbstractTrainer._train_and_save\u001b[1;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1815\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_single(X_w_pseudo, y_w_pseudo, model, X_val, y_val, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1817\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_single(X, y, model, X_val, y_val, total_resources\u001b[38;5;241m=\u001b[39mtotal_resources, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1819\u001b[0m fit_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_evaluation:\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1763\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single\u001b[1;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, model: AbstractModel, X_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, total_resources\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_fit_kwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AbstractModel:\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m \u001b[38;5;124;03m    Trains model but does not add the trained model to this Trainer.\u001b[39;00m\n\u001b[0;32m   1761\u001b[0m \u001b[38;5;124;03m    Returns trained model object.\u001b[39;00m\n\u001b[0;32m   1762\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1763\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, X_val\u001b[38;5;241m=\u001b[39mX_val, y_val\u001b[38;5;241m=\u001b[39my_val, total_resources\u001b[38;5;241m=\u001b[39mtotal_resources, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py:854\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_fit_resources(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_fit_memory_usage(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 854\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    856\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py:165\u001b[0m, in \u001b[0;36mStackerEnsembleModel._fit\u001b[1;34m(self, X, y, compute_base_preds, time_limit, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     time_limit \u001b[38;5;241m=\u001b[39m time_limit \u001b[38;5;241m-\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, time_limit\u001b[38;5;241m=\u001b[39mtime_limit, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py:273\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit\u001b[1;34m(self, X, y, X_val, y_val, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, groups, _skip_oof, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;66;03m# Reserve time for final refit model\u001b[39;00m\n\u001b[0;32m    272\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m folds_to_fit \u001b[38;5;241m/\u001b[39m (folds_to_fit \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.2\u001b[39m)\n\u001b[1;32m--> 273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_folds(\n\u001b[0;32m    274\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    275\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    276\u001b[0m     model_base\u001b[38;5;241m=\u001b[39mmodel_base,\n\u001b[0;32m    277\u001b[0m     X_pseudo\u001b[38;5;241m=\u001b[39mX_pseudo,\n\u001b[0;32m    278\u001b[0m     y_pseudo\u001b[38;5;241m=\u001b[39my_pseudo,\n\u001b[0;32m    279\u001b[0m     k_fold\u001b[38;5;241m=\u001b[39mk_fold,\n\u001b[0;32m    280\u001b[0m     k_fold_start\u001b[38;5;241m=\u001b[39mk_fold_start,\n\u001b[0;32m    281\u001b[0m     k_fold_end\u001b[38;5;241m=\u001b[39mk_fold_end,\n\u001b[0;32m    282\u001b[0m     n_repeats\u001b[38;5;241m=\u001b[39mn_repeats,\n\u001b[0;32m    283\u001b[0m     n_repeat_start\u001b[38;5;241m=\u001b[39mn_repeat_start,\n\u001b[0;32m    284\u001b[0m     save_folds\u001b[38;5;241m=\u001b[39msave_bag_folds,\n\u001b[0;32m    285\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    287\u001b[0m )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# FIXME: Cleanup self\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# FIXME: Support `can_refit_full=False` models\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refit_folds:\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py:689\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit_folds\u001b[1;34m(self, X, y, model_base, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, time_limit, sample_weight, save_folds, groups, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold_fit_args \u001b[38;5;129;01min\u001b[39;00m fold_fit_args_list:\n\u001b[0;32m    688\u001b[0m     fold_fitting_strategy\u001b[38;5;241m.\u001b[39mschedule_fold_model_fit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfold_fit_args)\n\u001b[1;32m--> 689\u001b[0m \u001b[43mfold_fitting_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_all_folds_scheduled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;66;03m# No need to add child times or save child here as this already occurred in the fold_fitting_strategy\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_child(model\u001b[38;5;241m=\u001b[39mmodel, add_child_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py:309\u001b[0m, in \u001b[0;36mSequentialLocalFoldFittingStrategy.after_all_folds_scheduled\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mafter_all_folds_scheduled\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs:\n\u001b[1;32m--> 309\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_fold_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py:314\u001b[0m, in \u001b[0;36mSequentialLocalFoldFittingStrategy._fit_fold_model\u001b[1;34m(self, fold_ctx)\u001b[0m\n\u001b[0;32m    312\u001b[0m time_start_fold \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    313\u001b[0m time_limit_fold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fold_time_limit(fold_ctx)\n\u001b[1;32m--> 314\u001b[0m fold_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_start_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_base_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m fold_model, pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_oof(fold_model, fold_ctx)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_bagged_ensemble(fold_model, pred_proba, fold_ctx)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py:349\u001b[0m, in \u001b[0;36mSequentialLocalFoldFittingStrategy._fit\u001b[1;34m(self, model_base, time_start_fold, time_limit_fold, fold_ctx, kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m     num_cpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_cpus, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_resources_per_job\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_cpus\u001b[39m\u001b[38;5;124m\"\u001b[39m, math\u001b[38;5;241m.\u001b[39minf))\n\u001b[0;32m    348\u001b[0m     num_gpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_gpus, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_resources_per_job\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_gpus\u001b[39m\u001b[38;5;124m\"\u001b[39m, math\u001b[38;5;241m.\u001b[39minf))\n\u001b[1;32m--> 349\u001b[0m fold_model\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX_fold, y\u001b[38;5;241m=\u001b[39my_fold, X_val\u001b[38;5;241m=\u001b[39mX_val_fold, y_val\u001b[38;5;241m=\u001b[39my_val_fold, time_limit\u001b[38;5;241m=\u001b[39mtime_limit_fold, num_cpus\u001b[38;5;241m=\u001b[39mnum_cpus, num_gpus\u001b[38;5;241m=\u001b[39mnum_gpus, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_fold)\n\u001b[0;32m    350\u001b[0m fold_model\u001b[38;5;241m.\u001b[39mfit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m time_start_fold\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fold_model\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py:854\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_fit_resources(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_fit_memory_usage(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 854\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    856\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py:218\u001b[0m, in \u001b[0;36mLGBModel._fit\u001b[1;34m(self, X, y, X_val, y_val, time_limit, num_gpus, num_cpus, sample_weight, sample_weight_val, verbosity, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_column in param dict is overridden.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m train_lgb_model(early_stopping_callback_kwargs\u001b[38;5;241m=\u001b[39mearly_stopping_callback_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrain_params)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m LightGBMError:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py:124\u001b[0m, in \u001b[0;36mtrain_lgb_model\u001b[1;34m(early_stopping_callback_kwargs, **train_params)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m booster\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrain_params)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lgb\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrain_params)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\lightgbm\\engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    269\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m    270\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    271\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[0;32m    272\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[0;32m    273\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[0;32m    274\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m--> 276\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\AutoGluon\\lib\\site-packages\\lightgbm\\basic.py:3658\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 3658\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3659\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   3661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   3662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 步驟1: 合併CSV檔案\n",
    "def combine_csv_files(folder_path):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            temp_df = pd.read_csv(file_path)\n",
    "            combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n",
    "    combined_df = combined_df.dropna()  # 刪除缺失值\n",
    "    return combined_df\n",
    "\n",
    "# 步驟3: 分割資料集\n",
    "def split_data(df):\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    return train_df, test_df\n",
    "\n",
    "# 步驟4: 使用AutoGluon訓練模型並啟用GPU加速\n",
    "def train_model(train_df, label_column='Signal'):\n",
    "    model_path = r\"D:\\Temp\\StockData\\model\\AutoGluon\\SwingTradeSignals\\SwingTrade-1\"\n",
    "    predictor = TabularPredictor(label=label_column, path=model_path).fit(train_data=train_df, presets='best_quality', num_gpus=1 ,\n",
    "                                                                          hyperparameters='extreme') # 為整個Tabular Predictor指定1個GPU\n",
    "    return predictor\n",
    "\n",
    "# 步驟5: 評估模型\n",
    "def evaluate_model(predictor, test_df):\n",
    "    predictor.leaderboard(test_df)  # 顯示模型的領導者榜\n",
    "    performance = predictor.evaluate(test_df)  # 評估模型的性能\n",
    "    best_model = predictor.model_best  # 顯示最佳模型\n",
    "    print(performance)\n",
    "    print(best_model)\n",
    "\n",
    "# 主程式\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = r\"D:\\Temp\\StockData\\US_STOCK_DATA\\TargetData\\subfolder_1\"  # 修改為你的資料夾路徑\n",
    "    combined_df = combine_csv_files(folder_path)\n",
    "    train_df, test_df = split_data(combined_df)\n",
    "    predictor = train_model(train_df, label_column='Signal')\n",
    "    evaluate_model(predictor, test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8502cf24",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6dba604",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6486dc00",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dcd600b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79de42bc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cea543f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a6cf17c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee0f09c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "464b9a6f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b6d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "\n",
    "# 預測並輸出結果到CSV\n",
    "def predict_and_export(predictor, data_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file_name in os.listdir(data_folder):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(data_folder, file_name)\n",
    "            data_df = pd.read_csv(file_path)\n",
    "            predictions = predictor.predict(data_df)\n",
    "            data_df['Predicted_Signal'] = predictions\n",
    "            output_path = os.path.join(output_folder, file_name)\n",
    "            data_df.to_csv(output_path, index=False)\n",
    "    print(\"All predictions exported successfully.\")\n",
    "\n",
    "\n",
    "# 主程式\n",
    "if __name__ == \"__main__\":\n",
    "    data_folder = r\"D:\\Temp\\StockData\\TW_STOCK_DATA\\tradeSignals\"  # 修改為你的資料夾路徑\n",
    "    output_folder = r\"D:\\Temp\\StockData\\TW_STOCK_DATA\\Output\"  # 設定輸出資料夾\n",
    "    model_path = r\"D:\\Temp\\StockData\\model\\AutoGluon\\SwingTradeSignals\\SwingTrade-1\"\n",
    "    predictor = TabularPredictor.load(model_path)  # 加載模型\n",
    "    predict_and_export(predictor, data_folder, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
